ETF_DataAnalysis

ä»¥ å°è‚¡ ETF ç‚ºæ ¸å¿ƒçš„è³‡æ–™å·¥ç¨‹å°ˆæ¡ˆï¼šå¾è³‡æ–™æ“·å–ã€æŒ‡æ¨™è¨ˆç®—åˆ° BigQuery / Metabase è¦–è¦ºåŒ–ï¼Œä¸¦ä»¥ Apache Airflow ç·¨æ’æ•´é«”æµç¨‹ã€‚å°ˆæ¡ˆè¨­è¨ˆé‡è¦–ã€Œæœ¬æ©Ÿå…ˆè·‘é€šã€å†ä¸Šé›²ã€çš„å­¸ç¿’æ›²ç·šã€‚

ğŸ—ï¸ æ¶æ§‹ç¸½è¦½

è³‡æ–™ä¾†æºï¼šTWSE APIï¼ˆETF æ­·å²æ—¥åƒ¹ã€é…æ¯ï¼‰

é‹ç®—ç·¨æ’ï¼šApache Airflowï¼ˆæ¯æ—¥æ’ç¨‹ï¼‰

è³‡æ–™åº«ï¼šMySQL 8ï¼ˆæ­é… phpMyAdminï¼‰

è³‡æ–™å€‰å„²ï¼šGoogle BigQueryï¼ˆRaw + Analyticsï¼‰

è¦–è¦ºåŒ–ï¼šMetabaseï¼ˆå„€è¡¨æ¿ï¼‰

å®¹å™¨åŒ–ï¼šDocker & Docker Compose

å¥—ä»¶ç®¡ç†ï¼šuvï¼ˆæ›´å¿«çš„ Python å¥—ä»¶ç®¡ç†ï¼‰

è³‡æ–™æµç¨‹

TWSE â†’ Python çˆ¬èŸ² â†’ MySQL â†’ metrics_pipeline â†’ (BigQuery ELT) â†’ Metabase
                     â†‘                                   â†“
                  Airflow DAG                    Analytics views / tables

ğŸ“ å°ˆæ¡ˆçµæ§‹
ETF_DataAnalysis/
â”œâ”€â”€ data_ingestion/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mysql.py                            # MySQL é€£ç·š & Schema & UPSERT
â”‚   â”œâ”€â”€ ETF_crawler_dividend.py             # ETF é…æ¯æŠ“å–ï¼ˆå½™ç¸½åŒæ—¥å¤šç­†ï¼‰
â”‚   â”œâ”€â”€ ETF_crawler_price.py                # ETF æ­·å²æ—¥åƒ¹ï¼ˆé€æœˆæŠ“å–ï¼Œé€£çºŒç©ºæœˆåœæï¼‰
â”‚   â”œâ”€â”€ metrics_pipeline.py                 # æŒ‡æ¨™è¨ˆç®— â†’ ç‰©åŒ–åˆ° etf_metrics_daily
â”‚   â”œâ”€â”€ bigquery.py                         # BigQuery å…±ç”¨å·¥å…·
â”‚   â”œâ”€â”€ etf_sync_mysql_to_bigquery.py       # MySQL â†’ BigQuery Raw åŒæ­¥
â”‚   â””â”€â”€ etf_bigquery_transform.py           # åœ¨ BigQuery å»º View / ç‰©åŒ–è¡¨
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ airflow.cfg
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose-airflow.yml
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ ETF_bigquery_etl_dag.py         # DAG: MySQL â†’ BQ â†’ è½‰æ›
â”‚
â”œâ”€â”€ docker-compose-mysql.yml                # MySQL + phpMyAdmin
â”œâ”€â”€ docker-compose-metabase.yml             # Metabase
â”œâ”€â”€ .env                                    # ç’°å¢ƒè®Šæ•¸ï¼ˆä¸å…¥ç‰ˆæ§ï¼‰
â”œâ”€â”€ pyproject.toml / uv.lock                # ä¾è³´ç®¡ç†ï¼ˆuvï¼‰
â””â”€â”€ README.md

ğŸ”§ å…ˆå‚™ç’°å¢ƒ

Python 3.10+ã€Docker Desktopã€uv

å»ºç«‹ Docker ç¶²è·¯ï¼ˆä¾›å¤šæœå‹™äº’é€šï¼‰

docker network create my_network


å®‰è£ä¾è³´

uv sync

ğŸŒ ç’°å¢ƒè®Šæ•¸ï¼ˆ.envï¼‰

ç¨‹å¼æœƒè®€å– .envï¼Œç¼ºçœæ™‚ä½¿ç”¨é è¨­å€¼ã€‚æ­¤æª” ä¸è¦é€²ç‰ˆæ§ã€‚

# Docker Hubï¼ˆAirflow è‡ªè¡Œ build çš„ image tagï¼‰
DOCKER_HUB_USER=chris

# MySQLï¼ˆçµ¦ä½ çš„ç¨‹å¼/ETL ä½¿ç”¨ï¼‰
MYSQL_HOST=127.0.0.1        # æœ¬æ©Ÿè·‘è…³æœ¬ç”¨ï¼›Airflow å®¹å™¨å…§æœƒè¦†å¯«ç‚º mysql
MYSQL_PORT=3306
MYSQL_DB=ETF
MYSQL_USER=app
MYSQL_PASSWORD=

# Metabaseï¼ˆæ‡‰ç”¨è¨­å®š DBï¼‰
MB_DB_USER=metabase
MB_DB_PASS=

# Airflow
AIRFLOW_ADMIN_USER=airflow
AIRFLOW_ADMIN_PASS=

# BigQuery / GCP
GCP_PROJECT_ID=etfproject20250923
BQ_DATASET_RAW=etf_raw
BQ_DATASET_ANALYTICS=etf_analytics
GOOGLE_APPLICATION_CREDENTIALS=/home/chris/ETF_DataAnalysis/key.json  # æœ¬æ©Ÿè·¯å¾‘ï¼›Airflow å…§æœƒæ›è¼‰åˆ° /opt/airflow/key.json

# æŒ‡æ¨™èˆ‡ä¿®æ­£åƒæ•¸
SPLIT_THRESHOLD=0.20   # æ‹†/åˆè‚¡åµæ¸¬ï¼ˆéé™¤æ¯æ—¥ä¸”è·³å‹•å¹…åº¦ï¼‰


æ³¨æ„

åœ¨ æœ¬æ©Ÿ åŸ·è¡Œ Python è…³æœ¬æ™‚ï¼ŒMYSQL_HOST=127.0.0.1ã€‚

åœ¨ Airflow å®¹å™¨ åŸ·è¡Œæ™‚ï¼ŒDAG æœƒå°‡ MYSQL_HOST è¦†å¯«ç‚º mysqlï¼ˆCompose æœå‹™åï¼‰ã€‚

ğŸ—„ï¸ å•Ÿå‹•æœå‹™
MySQL + phpMyAdmin
docker compose -f docker-compose-mysql.yml up -d
# phpMyAdmin: http://localhost:8000


Compose å…§å·²è¨­ --max_allowed_packet=128Mï¼Œé¿å…å»ºç«‹å¤§å‹ VIEW æ™‚æ–·ç·šã€‚

Metabase
docker compose -f docker-compose-metabase.yml up -d
# Web: http://localhost:3000
# é¦–æ¬¡ç™»å…¥å¾Œæ–°å¢ MySQL é€£ç·šï¼ˆèˆ‡ .env ç›¸åŒï¼‰

Airflowï¼ˆDAG æ’ç¨‹ï¼‰
# build å°ˆç”¨ Airflow imageï¼ˆå…§å«æœ¬å°ˆæ¡ˆä¾è³´èˆ‡ dagsï¼‰
docker compose -f airflow/docker-compose-airflow.yml build --no-cache

# å•Ÿå‹•
docker compose -f airflow/docker-compose-airflow.yml up -d
# Web: http://localhost:8080  

# é¦–æ¬¡åˆå§‹åŒ–ï¼ˆè‹¥å°šæœª initï¼‰
docker compose -f airflow/docker-compose-airflow.yml up -d airflow-init

ğŸš€ æœ¬æ©ŸåŸ·è¡Œæµç¨‹ï¼ˆä¸èµ° Airflowï¼‰

å»ºè­°å…ˆè¼‰å…¥ .envï¼ˆæˆ–æ¯æ¢ uv run å¾ŒåŠ  --env-file .envï¼‰

# 1) è¼‰å…¥ç’°å¢ƒè®Šæ•¸
source .env

# 2) æŠ“ ETF é…æ¯
uv run -m data_ingestion.ETF_crawler_dividend

# 3) æŠ“ ETF æ­·å²æ—¥åƒ¹
uv run -m data_ingestion.ETF_crawler_price

# 4) è¨ˆç®—æŒ‡æ¨™ â†’ ç‰©åŒ– etf_metrics_daily
uv run -m data_ingestion.metrics_pipeline

â˜ï¸ BigQueryï¼šè¼•é‡ ELT

ç›®æ¨™åªæ˜¯ã€Œè­‰æ˜ä½ æœƒç”¨ BigQueryã€ï¼Œå› æ­¤æ¡ç”¨ è¼•é‡ ELTï¼š

åŒæ­¥ï¼šæŠŠ MySQL ä¸‰å¼µè¡¨ä¸Šå‚³è‡³ BQ_DATASET_RAW

etf_day_priceï¼ˆåˆ†å€ï¼štrade_dateï¼›å¢é›†ï¼štickerï¼‰

etf_dividendï¼ˆåˆ†å€ï¼šex_dateï¼›å¢é›†ï¼štickerï¼‰

etf_metrics_dailyï¼ˆåˆ†å€ï¼štrade_dateï¼›å¢é›†ï¼štickerï¼‰

è½‰æ›ï¼šåœ¨ BigQuery å»º è¦–åœ–èˆ‡ç‰©åŒ–è¡¨ï¼ˆä¾› Metabase / æŸ¥è©¢ï¼‰

1) æœ¬æ©Ÿç›´è·‘
# å®‰è£ BQ ç›¸é—œå¥—ä»¶ï¼ˆè‹¥æœªå®‰è£ï¼‰
uv add google-cloud-bigquery pandas pyarrow pandas-gbq pymysql SQLAlchemy

# åŒæ­¥ MySQL â†’ BigQuery Raw
uv run --env-file .env -m data_ingestion.etf_sync_mysql_to_bigquery

# å»º view / ç‰©åŒ–è¡¨ï¼ˆAnalyticsï¼‰
uv run --env-file .env -m data_ingestion.etf_bigquery_transform

2) ç”¨ Airflow è·‘ï¼ˆæ¨è–¦ï¼‰

DAGï¼šairflow/dags/ETF_bigquery_etl_dag.py

æµç¨‹ï¼š

sync_mysql_to_bigquery  â†’  bigquery_transform


åœ¨å®¹å™¨å…§ï¼ŒDAG æœƒè‡ªå‹•è¨­å®šï¼š

MYSQL_HOST=mysqlï¼ˆèˆ‡ Compose æœå‹™åŒåï¼‰

GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/key.json

ğŸ—„ï¸ è³‡æ–™è¡¨èªªæ˜
etf_dividendï¼ˆå”¯ä¸€éµï¼šticker + ex_dateï¼‰

ticker, short_name, ex_date, record_date, payable_date

cash_dividendï¼ˆå°æ•¸ï¼›åŒæ—¥å¤šç­†å·²å½™ç¸½ï¼‰

created_at, updated_at

etf_day_priceï¼ˆå”¯ä¸€éµï¼šticker + trade_dateï¼‰

volume, amountï¼ˆæ•´æ•¸ï¼‰

open, high, low, closeï¼ˆå°æ•¸ï¼‰

adjusted_closeï¼ˆç”± pipeline è¨ˆç®—ï¼‰

trades, created_at, updated_at

etf_metrics_dailyï¼ˆå”¯ä¸€éµï¼šticker + trade_dateï¼‰

adjusted_close, daily_return

vol_252ã€sharpe_252dã€tri_total_return

drawdown, mdd

dividend_12m, dividend_yield_12m

ğŸ“ æŒ‡æ¨™èªªæ˜ï¼ˆmetrics_pipeline.py â†’ etf_metrics_dailyï¼‰

æ‰€æœ‰æŒ‡æ¨™éƒ½ä»¥ é‚„åŸåƒ¹ adjusted_close ç‚ºåŸºç¤ï¼›æ¯å¤©ä¸€ç­†ã€‚

adjusted_close â€” é‚„åŸåƒ¹
æŠŠæ‹†/åˆè‚¡ã€é…æ¯ç­‰è·³å‹•èª¿æ•´æ‰ï¼Œè®“å ±é…¬ç‡é€£çºŒå¯æ¯”ã€‚

éé™¤æ¯æ—¥ã€ä¸”æ¼²è·Œå¹…è¶…é SPLIT_THRESHOLDï¼ˆé è¨­ 0.20ï¼‰â†’ è¦–ç‚ºæ‹†/åˆè‚¡ï¼Œå‘å‰å›æ¨æ¯”ä¾‹èª¿æ•´ã€‚

é™¤æ¯æ—¥ä»¥ç¾é‡‘è‚¡åˆ©åšåƒ¹æ ¼é‚„åŸã€‚

daily_return â€” æ—¥å ±é…¬ç‡
å…¬å¼ï¼š(adj_t / adj_{t-1}) - 1ï¼›é¦–æ—¥ç„¡å‰å€¼ç‚º NULLã€‚

vol_252 â€” å¹´åŒ–æ³¢å‹•åº¦ï¼ˆ252 äº¤æ˜“æ—¥ï¼‰
å…¬å¼ï¼šstd(daily_return_{252}) * sqrt(252)ï¼›è¦–çª—ä¸è¶³ç‚º NULLã€‚

sharpe_252d â€” å¹´åŒ–å¤æ™®å€¼ï¼ˆ252 äº¤æ˜“æ—¥ï¼‰
å…¬å¼ï¼š(mean(daily_return_{252}) / std(daily_return_{252})) * sqrt(252)ï¼›RF é è¨­ 0ã€‚

tri_total_return â€” æˆç«‹ä»¥ä¾†ç´¯ç©å ±é…¬ï¼ˆTRI-1ï¼‰
å…¬å¼ï¼šÎ  (1 + daily_return) - 1ï¼›è‡ªè©²æª” ETF ç¬¬ä¸€ç­†è³‡æ–™èµ·ç´¯ä¹˜ã€‚

drawdown â€” å›æ’¤
å…¬å¼ï¼šadj_t / max(adj_{â‰¤t}) - 1ï¼›æ–°é«˜ç‚º 0ï¼Œä½æ–¼æ–°é«˜ç‚ºè² å€¼ã€‚

mdd â€” æœ€å¤§å›æ’¤
å…¬å¼ï¼šmin(drawdown_{â‰¤t})ï¼›ä¾‹å¦‚ -0.45 ä»£è¡¨æ­·å²æœ€æ·±è·Œ 45%ã€‚

dividend_12m â€” è¿‘ 12 å€‹æœˆç¾é‡‘è‚¡åˆ©ç¸½é¡
åŒ¯ç¸½ etf_dividend.cash_dividend è¿‘ 365 å¤©ï¼ˆå«ç•¶æ—¥ï¼‰ï¼›ç„¡é…æ¯ç‚º 0ã€‚

dividend_yield_12m â€” è¿‘ 12 å€‹æœˆæ®–åˆ©ç‡
å…¬å¼ï¼šdividend_12m / adjusted_closeï¼›ä»¥ç•¶æ—¥åƒ¹è¡¡é‡ TTM æ®–åˆ©ç‡ã€‚

ğŸ“Š Metabase å„€è¡¨æ¿ï¼ˆå»ºè­°ï¼‰

å•Ÿå‹•ï¼šdocker compose -f docker-compose-metabase.yml up -d

æ–°å¢ MySQL /ï¼ˆå¯é¸ï¼‰BigQuery é€£ç·š

ä»¥ etf_metrics_daily èˆ‡ vw_metrics_daily åšæ¢ç´¢åœ–è¡¨

å¿«é€Ÿé¢æ¿ï¼š

å–®æª” ETFï¼šè¿‘ä¸€å¹´ adjusted_closeã€drawdownã€dividend_yield_12m

æ©«å‘æ¯”è¼ƒï¼šå¤šæª” ETF çš„ vol_252ã€sharpe_252dã€mdd

ğŸ› ï¸ ç–‘é›£æ’è§£

MySQL æ–·ç·š / å¤§çµæœé›†
å·²åœ¨ Compose è¨­ --max_allowed_packet=128Mï¼›å¿…è¦æ™‚é‡å»ºï¼š

docker compose -f docker-compose-mysql.yml up -d --force-recreate


Airflow DAG ä¸€ç›´å¤±æ•—

æª¢æŸ¥ Scheduler å®¹å™¨å…§ç’°å¢ƒï¼š

docker compose -f airflow/docker-compose-airflow.yml exec airflow-scheduler bash -lc '
  grep -E "GCP_PROJECT_ID|GOOGLE_APPLICATION_CREDENTIALS|MYSQL_HOST" /opt/airflow/.env || true
  getent hosts mysql || true
  ls -l /opt/airflow/key.json || true
  python3 -c "import google.cloud.bigquery,pyarrow,pandas,pymysql,sqlalchemy;print(\"deps OK\")"
'


æ‰‹å‹•åœ¨å®¹å™¨å…§è·‘è…³æœ¬çœ‹éŒ¯èª¤ï¼š

docker compose -f airflow/docker-compose-airflow.yml exec airflow-scheduler bash -lc '
  set -a; source /opt/airflow/.env; set +a
  export PYTHONPATH=/opt/airflow
  python3 -m data_ingestion.etf_sync_mysql_to_bigquery
  python3 -m data_ingestion.etf_bigquery_transform
'


BigQuery æ¬Šé™éŒ¯èª¤
ç¢ºèª .env çš„é‡‘é‘°è·¯å¾‘èˆ‡å®¹å™¨å…§ /opt/airflow/key.json ä¸€è‡´ï¼Œä¸¦ä¸” SA å…·å‚™ BigQuery Admin / Job User / Storage Viewer ç­‰å¿…è¦æ¬Šé™ã€‚

ğŸ“¦ ç‰ˆæœ¬æ§èˆ‡æäº¤

æé†’ï¼šæŠŠ key.jsonã€.env åŠ é€² .gitignoreï¼Œä¸è¦ push æ†‘è­‰ã€‚

git add .
git commit -m "docs+feat: BigQuery è¼•é‡ ELTã€Airflow DAGã€metrics æŒ‡æ¨™èªªæ˜èˆ‡å•Ÿå‹•æ–‡ä»¶"
git push

ğŸ“š é™„éŒ„ï¼šå¸¸ç”¨æŒ‡ä»¤é€ŸæŸ¥
# å¥—ä»¶
uv sync
uv add google-cloud-bigquery pandas pyarrow pandas-gbq pymysql SQLAlchemy

# æœ¬æ©ŸåŸ·è¡Œ
source .env
uv run -m data_ingestion.ETF_crawler_dividend
uv run -m data_ingestion.ETF_crawler_price
uv run -m data_ingestion.metrics_pipeline
uv run -m data_ingestion.etf_sync_mysql_to_bigquery
uv run -m data_ingestion.etf_bigquery_transform

# Docker
docker network create my_network
docker compose -f docker-compose-mysql.yml up -d
docker compose -f docker-compose-metabase.yml up -d
docker compose -f airflow/docker-compose-airflow.yml build --no-cache
docker compose -f airflow/docker-compose-airflow.yml up -d